{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import bigrams, trigrams\n",
    "from collections import Counter, defaultdict\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val = train_test_split(df['text'], test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    # remove punctuations\n",
    "    newString = re.sub(\"^[\\uFE70-\\uFEFF]\", \" \", text)\n",
    "    newString = re.sub(r\"[.،\\\"()0-9:A-Za-z,!%-/؟'ّ»ـ»'ً«'ُ'ْ'َ'ٍ{}؛'ِ'ٌ…\\\\|\\xad”@_?<>’“\\]\\[éà=‘]\",\"\",newString)\n",
    "    \n",
    "    words=[]\n",
    "    for i in newString.split():\n",
    "        i.strip()\n",
    "        words.append(i)\n",
    "    return (\" \".join(words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a placeholder for model\n",
    "def func_one():\n",
    "    return 0\n",
    "def func_two():\n",
    "    return defaultdict(func_one)\n",
    "\n",
    "model = defaultdict(func_two)\n",
    "\n",
    "# Make a vocab\n",
    "vocab = set()\n",
    "\n",
    "# Count frequency of co-occurance  \n",
    "for sentence in X_tr:\n",
    "    \n",
    "    if sentence != None:\n",
    "        sentence = text_cleaner(sentence)\n",
    "        words = sentence.split()\n",
    "        vocab.update(words)\n",
    "        for w1, w2, w3 in trigrams(words, pad_right=True, pad_left=True):\n",
    "            model[(w1, w2)][w3] += 1\n",
    "        for w1, w2 in bigrams(words, pad_right=True, pad_left=True):\n",
    "            model[w1][w2] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "def perplexity(data,smoothing_alpha = 0.001):\n",
    "    perplex = 0\n",
    "    num = 0\n",
    "    for sentence in data:\n",
    "    \n",
    "        if sentence != None:\n",
    "            sentence = text_cleaner(sentence)\n",
    "            words = [None,None] + sentence.split() + [None,None]\n",
    "      \n",
    "        for i in range(2,len(words)):\n",
    "            if (words[i-2], words[i-1]) in model.keys():\n",
    "                if words[i] in model[(words[i-2], words[i-1])].keys():\n",
    "                    count = model[(words[i-2], words[i-1])][words[i]]\n",
    "                    total = sum(model[(words[i-2], words[i-1])].values())\n",
    "                else:\n",
    "                    count = 1\n",
    "                    total = sum(model[(words[i-2], words[i-1])].values()) + 1\n",
    "          \n",
    "                prob = (count + smoothing_alpha) / (total + (len(vocab)*smoothing_alpha))\n",
    "            \n",
    "            elif words[i-1] in model.keys():\n",
    "                if words[i] in model[words[i-1]].keys():\n",
    "                    count = model[words[i-1]][words[i]]\n",
    "                    total = sum(model[words[i-1]].values())\n",
    "                else:\n",
    "                    count = 1\n",
    "                    total = sum(model[words[i-1]].values()) + 1\n",
    "          \n",
    "                prob = (count + smoothing_alpha) / (total + (len(vocab)*smoothing_alpha))\n",
    "        \n",
    "            else:\n",
    "                count = 0\n",
    "                total = 1\n",
    "          \n",
    "                prob = random.random() / len(vocab)\n",
    "            \n",
    "            num = num + 1\n",
    "            perplex = perplex + math.log(prob,2)\n",
    "      \n",
    "    return math.pow(2, -1*(perplex/num))\n",
    "\n",
    "perplexity(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's transform the counts to probabilities\n",
    "for w1_w2 in model:\n",
    "    total_count = float(sum(model[w1_w2].values()))\n",
    "    for w3 in model[w1_w2]:\n",
    "        model[w1_w2][w3] /= total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting words\n",
    "text = ['قررت','المحكمة']\n",
    "if tuple(text[-2:]) in model.keys():\n",
    "    words = sorted(model[tuple(text[-2:])], key=model[tuple(text[-2:])].get, reverse=True)[:3]\n",
    "    text.append(words[0])\n",
    "\n",
    "elif text[-1:][0] in model.keys():\n",
    "    words = sorted(model[text[-1:][0]], key=model[text[-1:][0]].get, reverse=True)[:3]\n",
    "    text.append(words[0])\n",
    "\n",
    "else:\n",
    "    words = []\n",
    "\n",
    "print(words)\n",
    "print (' '.join([t for t in text if t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
